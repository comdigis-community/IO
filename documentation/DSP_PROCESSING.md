#### Signal processing fundamentals

In **I/O**, the audio flow is organized as a directed acyclic graph evaluated in fixed blocks (*render quanta*) over an authoritative sampling clock. Each block advances an integer **timebase** in samples and enables deterministic scheduling based on a stable topological order: dependencies (fan-in) are resolved first, then each node’s *kernel* is executed, and finally the resulting buffers are published to downstream consumers. This cycle avoids *read-after-write hazards* and guarantees that, given identical inputs and the same internal state, the output is reproducible. The *scheduler* maintains one active view of the graph during render and applies topology updates at safe block boundaries, so changes do not interrupt real-time processing.

The engine is based on a **deterministic render loop**, where the audio graph is evaluated as a function of the context’s global *sampleRate*. Each node receives a fixed slice of the stream, avoiding race conditions and maintaining precise synchronization across all components. This block-based architecture ensures that real-time audio processing remains temporally stable even under high CPU load. The result is a system with predictable latency, where each operation has a bounded execution window and the graph’s behavior is reproducible frame by frame.

#### DSP kernel implementation and processing pipeline

Each node encapsulates a **DSP kernel** with explicit internal state and well-defined *prepare*, *process*, and *commit* contracts. During *prepare*, formats are validated (channel count, *stride*, alignment) and working memory is reserved to avoid runtime allocation in the render path. In *process*, transformations are optimized for modern CPU vectorization and cache locality. The *commit* phase publishes state changes and counters needed for subsequent blocks. This three-phase design enables *pipelining* between nodes, reduces intermediate latencies, and improves data locality in long processing chains.

The **numerical pipeline** prioritizes stability and precision: operators with accumulation (IIR filters, bus summing, RMS detectors) may use higher-precision arithmetic when the cost is justified, while the main signal path remains in *Float32* to maximize throughput and reduce memory pressure. dB↔linear conversions, *panning laws*, and scaling apply safe lower bounds to avoid denormals and preserve smooth gradients in low-level signals. Parameter *rampers* provide **sample-accurate** automation with *a-rate* (per-sample interpolation) and *k-rate* (per-block stepping), selected according to perceptual sensitivity and computational cost.

High-cost operations—convolution, *phase vocoding*, spectral analysis—use **partitioned FFT** with overlap strategies tuned to the context’s block size. The engine prepares FFT resources ahead of time and reuses processing buffers to avoid heap pressure. For long-tail convolution (reverbs, HRTFs), low-latency early partitions and efficient larger tail partitions are combined, with smooth crossfades when responses change.

Block-based processing guarantees stable and scalable execution, as each *kernel* operates on temporary buffers located in contiguous memory. The graph can thus scale to a high node count while maintaining predictable latency, with CPU and memory resources distributed evenly across the render cycle.

#### Optimization strategies and efficient CPU usage

**Memory management** is explicit and *RT-safe*. Buffers are aligned and reusable, and no allocations, frees, or blocking I/O occur on the audio thread. Resource loading and deserialization are handled on non-real-time threads. Buffer ownership is kept simple during each block to reduce synchronization overhead. **Inter-plane communication** uses non-blocking messaging between control and render contexts. Requests for graph changes, bulk parameter updates, or resource loading are *batched* and *coalesced*, and applied only at block boundaries. Any operation that compromises determinism (blocking system calls, sleeps, non-deterministic waits) is prohibited within the render callback. During render, recoverable anomalies can result in explicit silence and diagnostic flags for deferred analysis. For **execution optimizations**, I/O prioritizes cache-friendly processing and selective parallelism where dependency rules allow it. Mixing paths use vectorized arithmetic where available, and denormal handling is configured to keep near-zero signal processing stable and predictable in cost. **Temporal synchronization** is governed by a discrete, sample-based *timeline* and a monotonic *clock*. Nodes can query frame offsets and remaining frames to perform look-ahead scheduling without relying on wall time. Asynchronous source drift and rate differences are compensated through resampling strategies designed to minimize audible artifacts.

#### Thread safety and render determinism guarantees

The **analysis subsystem** in I/O operates in parallel with the mixing path without affecting latency or perceptual phase. Analysis nodes compute spectra, waveform snapshots, and level metrics for visualization and diagnostics. These taps operate on read-only views of render data, with control-plane throttling to align with visualization rates. **Numerical quality and robustness** include defenses against *NaN/Inf propagation*, gain limits, and optional safety soft-clipping at master stages, preserving headroom for dense mixes. dB↔linear converters preserve monotonicity and continuity near zero, and crossfade envelopes are designed for stable perceived energy. From a **testing and observability** perspective, I/O provides deterministic offline rendering workflows, reproducible fixtures (impulses, sweeps, noise), and signal probes at graph points for offline inspection. Performance profiling by node and regression checks for latency and energy behavior are used to maintain quality over time. This set of decisions—block-stable graph execution, explicit-state kernels, non-blocking messaging, preallocated memory, partitioned FFT, and sample-accurate automation—lays the foundation for extending the engine toward **advanced spatial audio** without compromising the critical path. Spatialization, in particular, requires distance-based attenuation, directivity, and smooth panning transitions; the timing model, ramp system, and memory discipline described here enable such transformations with temporal consistency and controlled cost.

#### License

This project is distributed under a license that allows its use, modification, and distribution, provided that the specified terms are respected (<http://opensource.org/licenses/mit-license.php>)

Copyright © 2019 - 2027 - ***Comdigis***, *Buenos Aires, Argentina*
